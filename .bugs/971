Title: apache_status agent plugin: Problem at split if more than one slash in output
Component: checks
Class: bug
State: done
Date: 2013-08-09 14:57:53
Targetversion: 1.2.3i2

I just installed the agents plugin apache_status (the version from release 1.2.2p2) on several of my machines.
On one of the machines it bugs however:
Traceback (most recent call last):
  File "./apache_status", line 83, in <module>
    servers = try_detect_servers()
  File "./apache_status", line 46, in try_detect_servers
    pid, proc = parts[6].split('/')
ValueError: too many values to unpack

After reading the source the problem is obvious: the output of the netstat command has entries
that have slashes in the command name:
----
# netstat -tlnp 2>/dev/null
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:30033           0.0.0.0:*               LISTEN      1326/./ts3server_li 
tcp        0      0 127.0.0.1:7505          0.0.0.0:*               LISTEN      1331/openvpn        
tcp        0      0 0.0.0.0:21              0.0.0.0:*               LISTEN      1333/tcpserver      
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      566/sshd            
tcp        0      0 0.0.0.0:10011           0.0.0.0:*               LISTEN      1326/./ts3server_li 
tcp6       0      0 :::80                   :::*                    LISTEN      12193/httpd         
tcp6       0      0 :::22                   :::*                    LISTEN      566/sshd            
tcp6       0      0 :::443                  :::*                    LISTEN      12193/httpd        
----
Note the ./ts3server_li entries.
Since there is more than 1 slash in the line, the split will return more than the expected 2 results.

2013-09-02 11:45:03: changed state open -> done
agent plugin apache_status now also works, if prog name contains slashes

2013-09-05: User did test, positive:
I've tried the new apache_status plugin on the server where it previously failed and it now seems to work 
So good job 
On servers that had no issues it still works as before as far as I can see (I've tested it on 3 servers).

